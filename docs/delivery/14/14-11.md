# [14-11] E2E CoS Test

[Back to task list](./tasks.md)

## Description

End-to-end testing of the complete Service Logs Viewer feature, verifying all Conditions of Satisfaction from the PBI are met. This comprehensive test ensures the entire logs viewing workflow functions correctly from backend to frontend.

## Status History

| Timestamp | Event Type | From Status | To Status | Details | User |
|-----------|------------|-------------|-----------|---------|------|
| 2025-10-04 00:00:00 | Created | N/A | Proposed | Task file created | ai-agent |

## Requirements

This task verifies all acceptance criteria from PBI 14:

1. Logs page accessible from environment detail view
2. Logs from all services in environment are aggregated
3. Logs displayed in chronological order
4. Real-time log streaming works via WebSocket
5. Users can filter logs by service (multi-select)
6. Users can filter logs by time range
7. Search functionality finds text across all displayed logs
8. Regex search mode is supported
9. Log severity levels are detected and color-coded
10. Users can export logs in JSON, CSV, and TXT formats
11. Virtual scrolling performs well with 10,000+ log lines
12. Auto-scroll can be toggled on/off
13. WebSocket reconnects automatically on connection loss
14. Empty state displayed when no logs available
15. Error handling for API failures with retry option

## Implementation Plan

### Test Environment Setup

1. **Prerequisites**:
   - Railway API token configured
   - Test environment with multiple services
   - Services generating logs
   - Backend API running
   - Frontend dev server running

2. **Test Data**:
   - Create test environment with 3+ services
   - Each service should have distinct logs
   - Mix of log levels (INFO, WARN, ERROR, DEBUG)
   - Sufficient log volume (100+ lines per service)

### Test Scenarios

#### Scenario 1: Basic Log Viewing

**Test**: Verify logs page accessible and displays logs
```
1. Navigate to project detail page
2. Select an environment
3. Click "Logs" tab
4. Verify:
   - Logs section loads
   - Historical logs displayed
   - Logs from all services shown
   - Logs in chronological order
   - Service badges visible
   - Timestamps formatted correctly
```

**Expected**: Logs displayed with service identification and timestamps

#### Scenario 2: Log Aggregation

**Test**: Verify multi-service log aggregation
```
1. Open logs for environment with 3+ services
2. Verify:
   - Logs from all services present
   - Service name badge on each log line
   - Different services identifiable by badge color
   - Chronological ordering across services
```

**Expected**: All service logs merged chronologically

#### Scenario 3: Real-time Streaming

**Test**: Verify WebSocket streaming functionality
```
1. Open logs section
2. Verify "Live" status indicator
3. Trigger new log in a service (e.g., make API call)
4. Verify:
   - New log appears within 5 seconds
   - No page refresh required
   - Auto-scroll works (if enabled)
```

**Expected**: New logs appear in real-time

#### Scenario 4: Service Filtering

**Test**: Verify service filter functionality
```
1. Open logs section with multiple services
2. Open service multi-select filter
3. Select one service only
4. Verify:
   - Only selected service's logs displayed
   - Other services filtered out
   - Filter count badge updates
5. Select all services
6. Verify all logs shown again
```

**Expected**: Service filter correctly includes/excludes logs

#### Scenario 5: Time Range Filtering

**Test**: Verify time range filtering
```
1. Open logs section
2. Select "Last 15 min" time range
3. Verify only recent logs shown
4. Select "Last 24 hours"
5. Verify older logs now visible
6. Select custom time range
7. Verify only logs in range shown
```

**Expected**: Time range filter limits logs correctly

#### Scenario 6: Text Search

**Test**: Verify search functionality
```
1. Open logs section
2. Enter search term (e.g., "error")
3. Verify:
   - Only matching logs displayed
   - Search term highlighted in yellow
   - Non-matching logs hidden
4. Clear search
5. Verify all logs visible again
```

**Expected**: Search filters and highlights matching logs

#### Scenario 7: Regex Search

**Test**: Verify regex search mode
```
1. Open logs section
2. Enable "Regex" toggle
3. Enter regex pattern (e.g., "error|fail")
4. Verify:
   - Logs matching regex pattern shown
   - Pattern highlighted
5. Enter invalid regex
6. Verify graceful fallback to plain text search
```

**Expected**: Regex search works with valid patterns

#### Scenario 8: Severity Detection and Color Coding

**Test**: Verify log level display
```
1. Open logs section
2. Locate logs with different severity levels
3. Verify:
   - ERROR logs have red highlight/border
   - WARN logs have yellow highlight/border
   - INFO logs have default/blue styling
   - DEBUG logs have muted styling
   - Severity badges visible
```

**Expected**: Severity levels visually distinguishable

#### Scenario 9: Log Export

**Test**: Verify export functionality for all formats
```
For each format (JSON, CSV, TXT):
1. Open logs section
2. Click "Export" button
3. Select format
4. Verify:
   - File download triggers
   - Filename includes environment name and timestamp
   - File contains expected logs
   - Format is correct (JSON structure, CSV columns, plain text)
```

**Expected**: Export produces valid files in all formats

#### Scenario 10: Virtual Scrolling Performance

**Test**: Verify performance with large log volumes
```
1. Generate or fetch 10,000+ log lines
2. Open logs section
3. Verify:
   - Initial load time < 2 seconds
   - Smooth scrolling (no lag)
   - Only visible logs rendered (check DevTools)
   - Memory usage reasonable (< 200MB)
4. Scroll to top and bottom rapidly
5. Verify smooth performance
```

**Expected**: Handles large volumes without performance degradation

#### Scenario 11: Auto-scroll Toggle

**Test**: Verify auto-scroll functionality
```
1. Open logs section (auto-scroll enabled by default)
2. Verify logs auto-scroll to bottom when new logs arrive
3. Scroll up manually
4. Verify auto-scroll disabled automatically
5. Toggle auto-scroll back on
6. Verify logs scroll to bottom
7. Verify new logs keep scrolling to bottom
```

**Expected**: Auto-scroll toggles correctly and respects user scroll

#### Scenario 12: WebSocket Reconnection

**Test**: Verify automatic reconnection
```
1. Open logs section (streaming enabled)
2. Verify "Live" status
3. Simulate network interruption:
   - Disconnect network or
   - Kill backend WebSocket temporarily
4. Verify "Connecting..." or "Disconnected" status
5. Restore network/backend
6. Verify:
   - Connection automatically restored
   - "Live" status returns
   - Streaming resumes
   - No duplicate logs
```

**Expected**: WebSocket reconnects automatically with exponential backoff

#### Scenario 13: Empty State

**Test**: Verify empty state display
```
1. Create new environment with no services or logs
2. Open logs section
3. Verify:
   - "No logs available" message displayed
   - Helpful text (e.g., "Deploy a service to see logs")
   - No error state
```

**Expected**: User-friendly empty state message

#### Scenario 14: Error Handling

**Test**: Verify error handling and retry
```
1. Stop backend API
2. Open logs section
3. Verify:
   - Error message displayed
   - "Retry" button visible
4. Restart backend API
5. Click "Retry" button
6. Verify:
   - Logs load successfully
   - Error state cleared
```

**Expected**: Graceful error handling with retry option

#### Scenario 15: Filter Persistence

**Test**: Verify filters persist via URL params
```
1. Open logs section
2. Apply multiple filters (service, time range, search)
3. Copy URL
4. Open URL in new tab
5. Verify filters restored from URL parameters
```

**Expected**: Filters shareable via URL

### Test Execution

1. **Manual Testing**:
   - Execute each scenario manually
   - Document results
   - Capture screenshots of issues

2. **Automated E2E Tests** (optional, using Playwright):
   ```typescript
   import { test, expect } from '@playwright/test'

   test('logs page accessible and displays logs', async ({ page }) => {
     await page.goto('/dashboard')
     
     // Select project and environment
     await page.click('text=Test Project')
     await page.click('text=production')
     
     // Navigate to logs tab
     await page.click('text=Logs')
     
     // Verify logs displayed
     await expect(page.locator('[data-testid="log-line"]').first()).toBeVisible()
     
     // Verify chronological order
     const timestamps = await page.locator('[data-testid="log-timestamp"]').allTextContents()
     // Assert timestamps are in order
   })

   test('real-time streaming works', async ({ page }) => {
     await page.goto('/project/test/logs')
     
     // Verify live status
     await expect(page.locator('text=Live')).toBeVisible()
     
     // Trigger new log (via API or action)
     // ...
     
     // Verify new log appears
     await expect(page.locator('text=New log message')).toBeVisible({ timeout: 5000 })
   })

   // ... more automated tests
   ```

## Verification

This task is complete when:

- [ ] All 15 acceptance criteria verified
- [ ] All test scenarios pass
- [ ] No critical bugs found
- [ ] Performance meets requirements
- [ ] Error handling graceful
- [ ] UI consistent with design
- [ ] Documentation updated
- [ ] Known issues documented

## Files Modified

- **New**: `docs/delivery/14/14-11-test-results.md` (test execution report)
- **New**: `e2e/logs.spec.ts` (if automated tests created)

## Test Report Template

```markdown
# PBI 14: Service Logs Viewer - E2E Test Results

**Test Date**: YYYY-MM-DD
**Tester**: Name
**Environment**: Local / Staging / Production
**Backend Version**: vX.Y.Z
**Frontend Version**: vX.Y.Z

## Summary
- **Total Scenarios**: 15
- **Passed**: X
- **Failed**: Y
- **Blocked**: Z

## Scenario Results

### 1. Basic Log Viewing
- **Status**: ✅ Pass / ❌ Fail
- **Notes**: ...

### 2. Log Aggregation
- **Status**: ✅ Pass / ❌ Fail
- **Notes**: ...

(Continue for all scenarios...)

## Issues Found
1. Issue description
   - **Severity**: Critical / Major / Minor
   - **Steps to Reproduce**: ...
   - **Expected**: ...
   - **Actual**: ...
   
## Recommendations
- ...

## Sign-off
- [ ] All critical issues resolved
- [ ] PBI ready for Done status
```

## Success Criteria

- All 15 CoS acceptance criteria verified as passing
- No critical or blocking issues
- Performance acceptable (virtual scrolling, streaming)
- Error handling and edge cases covered
- Test report completed and reviewed

